{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MATH 405/607 \n",
    "\n",
    "# Numerical Methods for Differential Equations\n",
    "\n",
    "[[Instructor: Christoph Ortner]](http://www.math.ubc.ca/~ortner/)  [[course page]](https://github.com/cortner/math405_2022)\n",
    "\n",
    "\n",
    "## Optimization Problems\n",
    "\n",
    "* Newton method again \n",
    "* Steepest descent\n",
    "* Line-search \n",
    "* outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "include(\"math405.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General Optimisation \n",
    "\n",
    "In optimisation we are given an objective $\\Phi : D \\to \\mathbb{R}$ and wish to solve \n",
    "$$ \n",
    "    \\min_{x \\in D} \\Phi(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Unconstrained Optimization \n",
    "\n",
    "Let $\\Phi : \\mathbb{R}^N \\to \\mathbb{R}$ and solve $\\min_{x \\in \\mathbb{R}^N} \\Phi(x)$.\n",
    "\n",
    "By this we mean that we with to find $x \\in \\mathbb{R}^N$ such that \n",
    "\n",
    "$$\n",
    "   f(x) \\leq f(x') \\qquad \\forall x' \\in \\mathbb{R}^N\n",
    "$$\n",
    "\n",
    "But usually we must be content with local minimizers - more on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Applications of Optimization \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization and Nonlinear Systems\n",
    "\n",
    "From calculus we know that we can solve the nonlinear system \n",
    "\n",
    "$$f(x) = \\nabla \\Phi(x) = 0$$ \n",
    "\n",
    "and then pick those roots that are minima (check that the hessian is positive definite). This is rarely a good strategy. Because the objective is scalar there are much more powerful tools available to solve optimisation problems than to solve nonlinear systems. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nevertheless, some ideas from nonlinear systems remain enourmously important in optimization as well; e.g. Newton's method now becomes \n",
    "\n",
    "$$\n",
    "   x_{n+1} = x_n - \\nabla^2 \\Phi(x_n) \\nabla \\Phi(x_n).\n",
    "$$\n",
    "\n",
    "* Of course, as in the nonlinear system case we obtain quadratic convergence. \n",
    "* As before the challenge remains to evaluate and invert the hessian matrix. While gradients are normally cheap to compute (cf. adjoint method = backpropagation) hessians are often very expensive.\n",
    "* Further, Newton's method may converge to maxima or saddle point since we have not built in any information about minimality into the method!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A First Optimization Scheme \n",
    "\n",
    "A general idea in optimization that incorporates the idea of minimality is to enforce decrease of the objective at every step, i.e., let $x_n \\to x_{n+1}$ be an optimization step then we require that \n",
    "\n",
    "$$\n",
    "   \\Phi(x_{n+1}) < \\Phi(x_n)\n",
    "$$\n",
    "\n",
    "(unless $x_n$ is already a minimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How should we create updates that achieve this? \n",
    "\n",
    "## Suggestions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A general idea: search in directions of descent: \n",
    "\n",
    "$$\n",
    "   x_{n+1} = x_n + \\alpha_n p_n\n",
    "$$\n",
    "\n",
    "where $p_n$ is a descent direction if \n",
    "\n",
    "$$\n",
    "   \\frac{d}{d\\alpha} \\Phi(x_n + \\alpha p_n) \\Big|_{\\alpha = 0} < 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is a good descent direction? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Direction of Steepest Descent\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\arg\\min_{\\|p\\| = 1} \\frac{d}{d\\alpha} \\Phi(x + \\alpha p) \\Big|_{\\alpha = 0}\n",
    "    &= \\arg\\min_{\\|p\\| = 1} \\nabla\\Phi(x) \\cdot p \n",
    "    = - \\frac{\\nabla\\Phi(x)}{\\| \\nabla \\Phi(x) \\|}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Usually we don't normalize (it will be clear in a moment!) We call \n",
    "\n",
    "$$\n",
    "     p = - \\nabla \\Phi(x)\n",
    "$$\n",
    "\n",
    "the direction of steepest descent.\n",
    "\n",
    "**WARNING:** The norm used for normalization $\\|p\\|=1$ determines what the steepest descent direction is. There are other options that lead to different directions but they are rarely used. (maybe unwisely...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Steepest Descent Method \n",
    "\n",
    "$$\n",
    "  x_{n+1} = x_n - \\alpha_n \\nabla \\Phi(x_n)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How should we choose $\\alpha_n$? \n",
    "\n",
    "Maybe we can first try with fixed $\\alpha_n \\equiv \\alpha$ and just experiment? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "function steepest_descent1(fgrad, x0, α; \n",
    "                           tol = 1e-3, maxiter = 100, verbose = true)\n",
    "    x = x0 \n",
    "    if verbose; @printf(\" iter |   |∇Φ| \\n\"); end \n",
    "    for n = 1:maxiter \n",
    "        g = fgrad(x)\n",
    "        if verbose; @printf(\" %4d |  %.2e \\n\", n, norm(g, Inf)); end \n",
    "        if norm(g, Inf) < tol \n",
    "            println(\"success: |g| < tol, iter = $n\")\n",
    "            return x \n",
    "        end \n",
    "        x = x - α * g \n",
    "    end\n",
    "    println(\"failure: iter > maxiter\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rosenbrock(x) =  (1.0 - x[1])^2 + 10.0 * (x[2] - x[1]^2)^2\n",
    "grad_rosenbrock(x) = ForwardDiff.gradient(rosenbrock, x)\n",
    "x0 = zeros(2)\n",
    "\n",
    "steepest_descent1(grad_rosenbrock, x0, 1e-1) # try other alpha? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# after a lot of fiddling ...\n",
    "steepest_descent1(grad_rosenbrock, x0, 1e-2, maxiter = 1_000, tol=1e-2, verbose = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* no fun fiddling with the parameters, we need a robust way to pick α\n",
    "* we needed a lot of iterations, there are much better choices of the search direction - to be discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backtracking Line Search \n",
    "\n",
    "If $\\Phi \\in C^2$ then \n",
    "\n",
    "$$\n",
    "    \\Phi(x + \\alpha p) = \\Phi(x) + \\alpha \\nabla \\Phi(x) \\cdot p + O(\\alpha^2)\n",
    "$$\n",
    "\n",
    "If $p$ is a descent direction, i.e., $\\nabla \\Phi(x) \\cdot p < 0$ then it immediately follows that $\\Phi(x + \\alpha p) < \\Phi(x)$ for $\\alpha$ sufficiently small. So why not keep reducing $\\alpha$ until this descent condition is satisfied? This is called backtracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In practice we actually enforce something stronger, called the **Armijo condition**: for some fixed parameter $0 < \\theta < 1$ we demand that  \n",
    "\n",
    "$$\n",
    "   \\Phi(x_n + \\alpha_n p_n) \\leq \\Phi(x_n) + \\theta \\alpha_n \\nabla \\Phi(x_n) \\cdot p_n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function steepest_descent2(ffun, fgrad, x0, α0; \n",
    "                           tol = 1e-3, maxiter = 100, verbose = true, \n",
    "                           θ = 0.01, αmin = 1e-8)\n",
    "    x = x0 \n",
    "    α = 0.0\n",
    "    if verbose; @printf(\" iter   α  |  |∇Φ|   Φ \\n\"); end \n",
    "    for n = 1:maxiter \n",
    "        # ------- steepest descent direction \n",
    "        f = ffun(x)\n",
    "        g = fgrad(x)\n",
    "        \n",
    "        # ------- remination criterion\n",
    "        if verbose; @printf(\" %4d %.2e |  %.2e  %.2e\\n\", n, α, norm(g, Inf), f); end \n",
    "        if norm(g, Inf) < tol \n",
    "            println(\"success: |g| < tol, iter = $n\")\n",
    "            return x \n",
    "        end \n",
    "\n",
    "        # ------- backtracking linesearch\n",
    "        α = α0\n",
    "        while ffun(x - α * g) > f - θ * α * dot(g, g)\n",
    "            α *= 0.5 \n",
    "            if α < αmin\n",
    "                println(\"failure: α < αmin\")\n",
    "                return x\n",
    "            end\n",
    "        end\n",
    "        x = x - α * g \n",
    "    end\n",
    "    println(\"failure: iter > maxiter\")\n",
    "    return x     \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "steepest_descent2(rosenbrock, grad_rosenbrock, x0, 1e-1; maxiter = 1_000, tol=1e-2, verbose=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* less fine-tuning. And even the remaining parameters, $\\alpha_0, \\theta$ can be removed with some additional analysis.\n",
    "* fewer iterations, though we now do more work per iteration, and still far from great ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposition:** Let $\\Phi \\in C^2$. The algorithm `steepest_descent2` but with the termination conditions removed produces a sequence $(x_n)_{n = 1, 2, \\dots}$ such that, *either* $\\Phi(x_n) \\downarrow - \\infty$, *or*, \n",
    "\n",
    "$$\n",
    "    \\nabla \\Phi(x_n) \\to 0 \\qquad \\text{as } n \\to \\infty\n",
    "$$\n",
    "\n",
    "**Proof:** see board/tablet/recording."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bigger Picture\n",
    "\n",
    "Numerical optimization is a very mature subject. There is therefore a vast number of possible optimisation algorithms or indeed classes of algorithms available. Some random examples: \n",
    "\n",
    "* (Nonlinear) conjugate gradients: enforce approximate orthogonality (in a specific metric) of subsequent search directions\n",
    "* Quasi-Newton methods: try to \"learn\" the hessian from the iteration history \n",
    "* numerous different line-search methods\n",
    "* trust-region methods: another class of methods that search in a ball instead of along a line\n",
    "* Gauss-Newton and Levenberg Marquardt for nonlinear least squares\n",
    "* Nelder-Mead: derivative-free optimization\n",
    "* stochastic gradient descent: specifically designed for ultra-large-scale parameter estimation problems (cf ANNs)\n",
    "\n",
    "... and many more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Optimization software is usually so mature that one should almost never write ones own code. \n",
    "In Julia, there are several nice optimization packages, with the standard package maybe being [`Optim.jl`](https://github.com/JuliaNLSolvers/Optim.jl): the following result speaks for itself ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Optim\n",
    "result = optimize(rosenbrock, zeros(2), BFGS())"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
